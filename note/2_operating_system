4.Concurrency and Threads.	Many hands make light work.

-----------------------------------------------------------------------------------------------
Thread Use Cases. What are threads useful for?
In a program, we can represent each concurrent task as a thread. Each thread provides the 
abstraction of sequential execution similar to the traditional programming model. In fact, we
can think of a traditional program as single-threaded with one logical sequence of steps as
each instruction follows the previous one. Each individual thread follows a single sequence of
steps as it executes statements, iterates through loops, calls/returns from procedures.

Four Reasons to Use Threads
	Program structure: expressing logically concurrent tasks.
	Responsiveness: shifting work to run in the background.
					Case:when writing a file, the operating system stores the modified
						 data in a kernel buffer, and returns immediately to the application.
						 In the background, the operating system kernel runs a separate thread
						 to flush the modified data out to disk.
	Performance: exploiting multiple processors.
				 An advantage to using threads for parallelism is that the number of threads
				 need not exactly match the number of processors in the hardware on which it
				 is runing. The operating system transparently switches which threads run on
				 which processors.
	Performance: managing I/O devices.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Thread Abstraction. What is the thread abstraction as seen by a programmer?

A thread is a single execution sequence that represents a separately schedulable task.
	a.Single execution sequence. Each thread executes a sequence of instructions just
	as in the familiar sequential programming model.
	b.Separately schedulable task. The operating system can run, suspend, or resume a thread at
	any time.

Running,Suspending,and Resuming Threads

Why "Unpredictable Speed"?
	We must coordinate thread actions through explicit synchronization rather than by trying
	to reason about their relative speed.

Is a kernel interrupt handler a thread?
No, an interrupt handler is not a thread. A kernel interrupt handler shares some resemblance
to a thread: it is a single sequence of instructions that executes from beginning to end. 
However, an interrupt handler is not independently schedulable: it is triggered by a hardware
I/O event, rather than a decision by the thread scheduler in the kernel. Once started, the
interrupt handler runs to completion, unless preempted by another interrupt.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Simple Thread API. How can programmers use threads?

void thread_create(thread,func,arg)
void pthread_create(thread,NULL,func,(void *)arg)
	Create a new thread, storing information about it in thread. Concurrently with the calling
	thread, thread executes the function func with the argument arg.

void thread_yield()
	The calling thread voluntarily gives up the processor to let some other thread(s) run. The
	scheduler can resume running the calling thread whenever it chooses to do so.

int thread_join(thread)
void pthread_join(thread,(void **)exitValue)
	Wait for thread to finish if it has not already done so; then return the value passed to
	thread_exit by that thread. Note that thread_join may be called only once for each thread.

void thread_exit(ret)
	Finish the current thread. Store the value ret in the current thread's data structure.
	If another thread is already waiting in a call to thread_join, resume it.

Creating and scheduling threads are separate operations. Although threads are usually scheduled
in the order that they are created, there is no guarantee. Further, even if thread 2 started
running before thread 5, it might be preempted before it reaches the printf call.

Why must the "Thread returned" message from thread 2 print before the Thread returned message
from thread 5?
Since the threads run on virtual processors with unpredictable speeds, the order in which the
threads finish is indeterminate. However, the main thread checks for thread completion in the
order they were created. It calls thread_join for thread i+1 only after thread_join for thread
i has return.

In practice, the operating system will often create a thread to run blockzero in the
background. The memory of an exiting process does not need to be cleared until the memory is
needed -- that is, when the next process is created.
To exploit this flexibility, the operating system can create a set of low priority threads to
run blockzero. The kernel can then return immediately and resume running application code.
Later on, when the memory is needed, the kernel can call thread_join. If the zero is complete
by that point, the join will return immediately; otherwise, it will wait until the memory is
safe to use.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Thread Data Structures and Life Cycle. 
What data structures does the operating system use to manage threads?

The operating system provides the illusion that each thread runs on its own virtual processor
by transparently suspending and resuming threads. For the illusion to work, the operating
system must precisely save and restore the state of a thread. However, because threads run
either in a process or in the kernel, there is also shared state that is not saved or restored
when switching the processor between threads.

 Shared State		   Thread 1's
					Per-Thread State
 ------------		|---------------|
|	 Code	 |		| Thread Control|
 ------------		|  Block(TCB)   |
					|---------------|
					|	  Stack		|
 ------------		|   Information	|
|	Global	 |		|---------------|
|  Varivbles |		|	  Saved		|
 ------------		|	Registers	|
					|---------------|
 ------------		|	  Thread	|
|	 Heap	 |		|    Metadata	|
 ------------		|---------------|
 

					|	  Stack 	|
					|...............|
					|...............|
					|---------------|

The thread control block stores the per-thread state:
	The current state of the thread's computation(e.g.,saved proecessor registers and a 
	pointer to the stack)
	and metadata needed to manage the thread(e.g.,the thread's ID,scheduling prority,owner,and
	resource consumption). 
Shared state includes the program's code, global static varibles, and the heap.

Per-Thread State and Thread Control Block(TCB)
	For every thread the operating system creates,it creates one TCB.
	The thread control block holds two types of per-thread information:
		1.The state of the computation being performed by the thread.
		2.Metadata about the thread that is used to manage the thread.

Per-thread Computation State.
	a pointer to the thread's stack and a copy of its processor registers.

	Stack: A thread's stack is the same as the stack for a single-threaded computation -- it
	stores information needed by the nested procedures the thread is currently running.
	When a new thread is created, the operating system allocates it a new stack and
	stores a pointer to that stack in the thread's TCB.

	Copy of processor registers: A processor's registers include not only its general-purpose
	registers for storing intermediate values for ongoing computations, but they also include
	special-purpose registers, such as the instruction pointer and stack pointer.
	In some systems, the general-purpose registers for a stopped thread are stored on the top
	of the stack, and the TCB contains only a pointer to the stack.In other systems, the TCB
	contains space for a copy of all processor registers.

Per-thread Metadata.
	The TCB also includes per-thread metadata -- information for managing the thread. For
	example, each thread might have a thread ID, scheduling priority, and status (e.g,
	whether the thread is waiting for an event or is ready to be placed onto a processor).

Shared State
	program code is shared by all threads in a process, although each thread may be executing
	at a different place within that code. Additionally, statically allocated global variables
	and dynamically allocated heap variables can store information that is accessible to all
	threads.

In addition to the per-thread state that corresponds to execution state in the single-threaded
case,some systems include additional thread-local variables.These variables are similar to
global variables in that their scope spans different procedures, but they differ in that each
thread has its own copy of these variables.
Errno. In a multi-threaded program,however,multiple threads can perform system calls
concurrently.Rather than redefine the entire UNIX system call interface for a multi-threaded
environment, errno is now a macro that maps to a thread-local variable containing the error
code for that thread's most recent system call.
Heap internals. for performance reasons heaps may internally subdivide their space int 
per-thread regions.The advantage of subdividing the heap is that multiple threads can each
allocate objects at the same time without interfering with one anoter.Further, by allocating
objects used by the same thread from the same memory region, cache hit rates may improve.To
implement these optimizations, each subdivision of the heap has thread-local variables that
track what parts of the thread-local heap are in use, what parts are free,and so on.
Then, the code that allocates new memory is written to use these thread-local data structures
and only take memory from the shared heap if the local heap is empty.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Thread Life Cycle. What states does a thread go through between initialization and completion?

INITï¼šThread creeation puts a thread into its INIT state and allocates and initializes 
per-thread data structures. Once that is done, thread creation code puts the thread into the
READY state by adding the thread to the ready list. In practice, the ready list is not in fact
a "list"; the operating system typically uses a more sophisticated data structure to keep 
track of runnable threads, such as a priority queue.

READY: Its TCB is on the ready list, and the values of its registers are stored in its TCB. At
any time, the scheduler can cause a thread to transition from READY to RUNNING by copying its
register values from its TCB to a processor's registers.

RUNNING: At this time, its register values are stored on the processor rathre than in the
TCB.A RUNNING thread can transition to the READY state in two ways:
	The scheduler can preempt a running thread and move it to the READY state by:
		1.saving the thread's registers to its TCB
		2.switching the processor to run the next thread on the ready list.
	A running thread can voluntarily relinquish the processor and go from RUNNING to READY by 
	calling yield (e.g.,thread_yield in the thread library).

WAITING: A thread in the WAITING state is waiting for some event. Whereas the scheduler can
move a thread in the READY state to the RUNNING state, a thread in the WAITING state cannot
run until some action by another moves it from WAITING to READY.After creating its children
threads, the main thread must wait for them complete, by calling thread_join once for each
child.If the specific child thread is not yet done at the time of the join, the main thread
goes from RUNNING to WAITING until the child thread exits.
While a thread waits for an event, it cannot make progress; therefore, it is not useful to run
it. Rather than continuing to run the thread or storing the TCB on the scheduler's ready list,
the TCB is stored on the waiting list of some synchronization variable associated with the 
event. When the required event occurs, the operating system moves the TCB from the
synchronization variable's waiting list to the scheduler's ready list, transitioning the thread
from WAITING to READY.

FINISHED: A thread in the FINISHED state never runs again. For example, the thread_exit call
lets a thread pass its exit value to its parent thread via thread_join.


Case: Where is my TCB?
A remarkably tricky implementation question is how to find the current thread's TCB. The thread
library needs access to the current TCB for a number of resons, e.g.,to change its priority or
to access thread-local variables.
The stack pointer is always unique to each thread. The thread library can store a pointer to
the thread TCB at the very bottom of the stack, underneath the procedure frames. (Some system
take this one step farther,and put the entire TCB at the bottom of the stack.) As long as
thread stacks are aligned to start at a fixed block boundary,the low order bits of the current
stack pointer can be masked to locate the pointer to the current TCB.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Implementing Kernel Threads. How do we implement the thread abstraction inside the operating
system kernel?

Kernel threads. A kernel thread executes kernel code and modifies kernel data structures.

Kernel threads and single-threaded processes. these processes can invoke system calls that run
concurrently with kernel threads inside the kernel.

Multi-threaded processes using kernel threads. Most operating systems provide a set of library
routines and system calls to allow applications to use multiple threads within a single
user-level process.

User-level threads.

Creating a Thread:
	
void thread_create(thread_t *thread, void (*func)(int), int arg){
	TCB *tcb = new TCB();
	thread->tcb = tcb;
	tcb->stack_size = INITIAL_STACK_SIZE;
	tcb->stack = new Stack(INITIAL_STACK_SIZE);

	tcb->sp = tcb->stack + INITIAL_STACK_SIZE;
	tcb->pc = stub;

	*(tcb->sp) = arg;
	tcb->sp--;
	*(tcb->sp) = func;
	tcb->sp--;

	thread_dummySwitchFrame(tcb);

	tcb->state = READY;
	readyList.add(tcb);
}

void stub(void (*func)(int), int arg){
	(*func) (arg);
	thread_exit(0);
}

There are three steps to creating a thread:

1.Allocate per-thread state. The first step in the thread constructor is to allocate space
for the thread's per-thread state: the TCB and stack

2.Initialize per-thread state. To initialize the TCB, the thread constructor sets the new
thread's registers to what they need to be when the thread starts RUNNING. The constructor
starts the thread in a dummy function,stub,which in turn calls func. We need this extra step
in case the func procedure returns instead of calling thread_exit.
To start at beginning of stub, the thread constructor sets up the stack as if stub was just
called by normal code;
In addition,we also push a dummy stack frame for thread_switch onto the stack.

3.Put TCB on ready list. The last step in creating a thread is to set its state to READY and
put the new TCB on the ready list, enabling the thread to be scheduled.

Deleting a Thread
When a thread calls thread_exit, there are two steps to deleting the thread:
	Remove the thread from the ready list so that it will never run again.
	Free the per-thread state allocated for the thread.

If a thread removes itself from the ready list and frees its own per-thread state, then the
program may break. For example, if a thread removes itself from the ready list but an interrupt
occurs before the thread finishes de-allocating its state, there is a memory leak: that thread
will never resume to de-allocate its state.
There is a simple fix: a thread never deletes its own state. Instead, some other thread must
do it. On exit, the thread transitions to the FINISHED state, moves its TCB from the ready list
to a list of finished threads the scheduler should never run. The thread can then safely
switch to the next thread on the ready list. Once the finished thread is no longer running, it
is safe for some other thread to free the state of the thread.

Thread Context Switch
We need to answer several questions:
	What triggers a context switch?
	How does a voluntary context switch (e.g., a call to thread_yield) work?
	How does an involuntary context switch differ from a voluntary one?
	What thread should the scheduler choose to run next?

What Triggers a Kernel Thread Context Switch?
	A thread context switch can be triggered by either a voluntary call into the thread library
	,or an involuntary interrupt or processor exception.

		Voluntary. most thread libraries provide a thread_yield call that lets the currently
		running thread voluntarily give up the processor to the next thread on the ready list.
		Similarly, the thread_join and thread_exit calls suspend execution of the current
		thread and start running a different one.

		Involuntary. An interrupt or processor exception could invoke an interrupt handler.

When switching between two threads, we need to temporatily defer interrupts until the switch is
complete to avoid confusion.
A subtle inconsistency might arise. Suppose a low priority thread is about to voluntarily
switch to a high priority thread. It pulls the high priority thread off the ready list, and
at that precise moment, an interrupt occurs. Suppose the interrupt moves a medium priority
thread from WAITING to READY. Since it appears that switches to the new thread. The high
priority thread is in limbo!
		
Voluntary Kernel Thread Context Switch

void thread_switch(oldThreadTCB, newThradTCB){
	pushad;
	oldThreadTCB->sp = %esp;
	%esp = newThreadTCB->sp;
	popad;
	return;
}
void thread_yield(){
	TCB *chosenTCB, *finishedTCB;

	disableInterrupts();

	chosenTCB = readyList.getNextThread();
	if(chosenTCB ==NULL){
		//Nothing else to run
	}els{
		runningThread->state = ready;
		readyList.add(runningThread);
		thread_switch(runningThread, chosenTCB);
		runningThread->state = running;
	}

	while((finishedTCB = finishedList->getNextThread()) != NULL){
		delete finishedTCB->stack;
		delete finishedTCB;
	}

	enableInterrupts();
}

void thread_dummySwitchFrame(newThread){
	*(tcb->sp) = stub;
	tcb->sp--;
	tcb->sp -= SizeOfPopad;
}

To create a new thread, thread_create must set up the stack of the new thread to be as if had
suspended execution just before performing its first instruction.
Then, if the newly created thread is the next thread to run, a thread can call thread_yield,
switch to the newly create thread, switch to its stack pointer, pop the register values off
the stack, and "return" to the new thread, even though it had never calledd switch in the 
first place.

Involuntary Kernel Thread Context Switch.
In short, comparing a switch between kernel threads to what happents on a user-mode transfer:
(1) there is no need to switch modes (and therefore no need to switch stacks)
(2) the handler can resume any thread on the ready list rather than always resuming the thread
	or process that was just suspended.

To be compatible with x86 interrupt hardware, the software implementation of thread_switch
would simulate the hardware case, saving the return instruction pointer and eflags register
before calling pushad to save the general-purpose registers.After switching to the new stack,
it would call iret to resume the new thread, whether the new thread was suspended by a
hardware event or a software call.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Combining Kernel Threads and Single-Threaded User Processes. How do we extend the
implementation of kernel threads to support simple-threaded processes?

A system with both kernel threads and single-threaded user processes.
The PCB has information about the process's address space; when a context switch occurs from
one process to another, the operating system must change the virtual memory mappings as well
as the register state.
Since the PCB and TCB each represent one thread, the kernel's ready list can contain a mix
of PCBs for processes and TCBs for kernel threads.When the scheduler chooses the next thread to
run, it can pick either kind.A thread switch is nearly identical whether switching between
kernels or switching between a process's thread and a kernel thread.
We can resume a process in the kernel using thread_switch.

Entering the handler. When an interrupt or exception occurs, if the processor detects that it 
is already in kernel mode, it just pushes the instruction pointer and eflags registers (but 
not the stack pointer) onto the existing stack. On the other hand, if the hardware detects that
it is switching from user-mode to kernel-mode, then the processor also changes the stack
pointer to the base of the interrupt stack and pushes the original stack pointer along with
the instruction pointer and eflags registers onto the new stack.

Returning from the handler. When the iret instruction is called, it inspects both the current
eflags register and the value on the stack that it will use to restore the earlier eflags
register. If the mode bit is identical, then iret just pops the instruction pointer and 
eflags register and continues to use the current stack. On the other hand, if the mode bit
differs, then the iret instruction pops not only the instruction pointer and eflags register,
but also the saved stack pointer, thus switching the processor's stack pointer to the saved
one.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Implementing Multi-threaded Processes. How do we implement the thread abstraction for 
multi-threaded applications?

Implementing Multi-Threaded Processes Using Kernel Threads.
The simplest way to support multiple threads per process is to use the kernel thread
implementation we have already described.

When a user-level thread accesses the thread library to do the same things, it uses a system
call to ask the kernel to do the operation on its behalf.
A thread in a process has:
	A user-level stack for executing user code.
	A kernel interrupt stack for when this thread makes system calls,causes a processor
	exception, or is interrupted.
	A kernel TCB for saving and restoring the per-thread state.
To create a thread, the user library allocates a user-level stack for the thread and then does
a system call into the kernel. The kernel allocates a TCB and interrupt stack, and arranges
the state of the thread to start execution on the user-level stack at the beginning of the
requested procedure.
After creating the thread, the krenel puts the new thread on the ready list, to be scheduled
like any other thread, and returns unique identifier for the user program to use when referring
to the newly created thread(e.g.,for join).
Thread join,yield,and exit work the same way: by calling into the kernel to perform the
requested function.

Implementing User-Level Threads Without Kernel Support
It is also possible to implement threads as a library completely at user level, without any
operating system support. JVM implemented what were called green threads, a pure user-level
implementation of threads.
The basic idea is simple. The thread library instantiates all of its data structures within
the process: TCBs, the ready list, the finished list, and the waiting lists all are just data
structures in the process's address space. Then, calls to the thread library are just procedure
calls, akin to how the same functions are implemented within a multi-threaded kernel.
To the operating system kernel, a multi-threaded application using green threads appears to be
a normal, single-threaded process. The process as a whole can make system calls, be time-sliced
,etc, Unlike with kernel threads, when a process using green threads is time-sliced, the entire
process,including all of its threads, is suspended.
A limitation of green threads is that the operating system kernel is unaware of the state of 
the user-level ready list. If the application performs a system call that blocks watiting for
I/O, the kernel is unable to run a different user-level thread.Likewise, on a multiprocessor,
the kernel is unable to run the different threads running within a single process on different
processors.
To implement preemptive multi-threading for some process P:
G1. The user-level thread library makes a system call to register a timer signal handler and
signal stack with the kernel.
G2. When a hardware timer interrupt occurs, the hardware saves P's register state and runs the
kernel's handler.
G3. Instead of restoring P's register state and resuming P where it was interrupted, the
kernel's handler copies P's saved registers onto P's signal stack.
G4. The kernel resumes execution in P at the registered signal handler on the signal stack.
G5. The signal handler copies the processor state of the preempted user-level thread from the
signal stack to that thread's TCB.
G6. The signal handler chooses the next thread to run, re-enables the signal handler(the 
equivalent of re-enabling interrupts), and restores the new thread's state from its TCB into
the processor. execution with the state(newly) stored on the signal stack.

Implementing User-Level Threads With Kernel Support
Various system take more of a hybrid model, attempting to combine the lightweight performance
and application control over scheduling found in user-level threads, while keeping many of the
advantages of kernel threads.
Hybrid Thread join.
	
Per-Processor Kernel Threads.
Scheduler Activations.
-----------------------------------------------------------------------------------------------



-----------------------------------------------------------------------------------------------
Alternative Abstractions. What other abstractions can we use to express and implement
concurrency?
-----------------------------------------------------------------------------------------------
