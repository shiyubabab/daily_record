4.Concurrency and Threads.	Many hands make light work.

-----------------------------------------------------------------------------------------------
Thread Use Cases. What are threads useful for?
In a program, we can represent each concurrent task as a thread. Each thread provides the 
abstraction of sequential execution similar to the traditional programming model. In fact, we
can think of a traditional program as single-threaded with one logical sequence of steps as
each instruction follows the previous one. Each individual thread follows a single sequence of
steps as it executes statements, iterates through loops, calls/returns from procedures.

Four Reasons to Use Threads
	Program structure: expressing logically concurrent tasks.
	Responsiveness: shifting work to run in the background.
					Case:when writing a file, the operating system stores the modified
						 data in a kernel buffer, and returns immediately to the application.
						 In the background, the operating system kernel runs a separate thread
						 to flush the modified data out to disk.
	Performance: exploiting multiple processors.
				 An advantage to using threads for parallelism is that the number of threads
				 need not exactly match the number of processors in the hardware on which it
				 is runing. The operating system transparently switches which threads run on
				 which processors.
	Performance: managing I/O devices.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Thread Abstraction. What is the thread abstraction as seen by a programmer?

A thread is a single execution sequence that represents a separately schedulable task.
	a.Single execution sequence. Each thread executes a sequence of instructions just
	as in the familiar sequential programming model.
	b.Separately schedulable task. The operating system can run, suspend, or resume a thread at
	any time.

Running,Suspending,and Resuming Threads

Why "Unpredictable Speed"?
	We must coordinate thread actions through explicit synchronization rather than by trying
	to reason about their relative speed.

Is a kernel interrupt handler a thread?
No, an interrupt handler is not a thread. A kernel interrupt handler shares some resemblance
to a thread: it is a single sequence of instructions that executes from beginning to end. 
However, an interrupt handler is not independently schedulable: it is triggered by a hardware
I/O event, rather than a decision by the thread scheduler in the kernel. Once started, the
interrupt handler runs to completion, unless preempted by another interrupt.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Simple Thread API. How can programmers use threads?

void thread_create(thread,func,arg)
void pthread_create(thread,NULL,func,(void *)arg)
	Create a new thread, storing information about it in thread. Concurrently with the calling
	thread, thread executes the function func with the argument arg.

void thread_yield()
	The calling thread voluntarily gives up the processor to let some other thread(s) run. The
	scheduler can resume running the calling thread whenever it chooses to do so.

int thread_join(thread)
void pthread_join(thread,(void **)exitValue)
	Wait for thread to finish if it has not already done so; then return the value passed to
	thread_exit by that thread. Note that thread_join may be called only once for each thread.

void thread_exit(ret)
	Finish the current thread. Store the value ret in the current thread's data structure.
	If another thread is already waiting in a call to thread_join, resume it.

Creating and scheduling threads are separate operations. Although threads are usually scheduled
in the order that they are created, there is no guarantee. Further, even if thread 2 started
running before thread 5, it might be preempted before it reaches the printf call.

Why must the "Thread returned" message from thread 2 print before the Thread returned message
from thread 5?
Since the threads run on virtual processors with unpredictable speeds, the order in which the
threads finish is indeterminate. However, the main thread checks for thread completion in the
order they were created. It calls thread_join for thread i+1 only after thread_join for thread
i has return.

In practice, the operating system will often create a thread to run blockzero in the
background. The memory of an exiting process does not need to be cleared until the memory is
needed -- that is, when the next process is created.
To exploit this flexibility, the operating system can create a set of low priority threads to
run blockzero. The kernel can then return immediately and resume running application code.
Later on, when the memory is needed, the kernel can call thread_join. If the zero is complete
by that point, the join will return immediately; otherwise, it will wait until the memory is
safe to use.
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
Thread Data Structures and Life Cycle. 
What data structures does the operating system use to manage threads?

The operating system provides the illusion that each thread runs on its own virtual processor
by transparently suspending and resuming threads. For the illusion to work, the operating
system must precisely save and restore the state of a thread. However, because threads run
either in a process or in the kernel, there is also shared state that is not saved or restored
when switching the processor between threads.

 Shared State		   Thread 1's
					Per-Thread State
 ------------		|---------------|
|	 Code	 |		| Thread Control|
 ------------		|  Block(TCB)   |
					|---------------|
					|	  Stack		|
 ------------		|   Information	|
|	Global	 |		|---------------|
|  Varivbles |		|	  Saved		|
 ------------		|	Registers	|
					|---------------|
 ------------		|	  Thread	|
|	 Heap	 |		|    Metadata	|
 ------------		|---------------|
 

					|	  Stack 	|
					|...............|
					|...............|
					|---------------|

The thread control block stores the per-thread state:
	The current state of the thread's computation(e.g.,saved proecessor registers and a 
	pointer to the stack)
	and metadata needed to manage the thread(e.g.,the thread's ID,scheduling prority,owner,and
	resource consumption). 
Shared state includes the program's code, global static varibles, and the heap.

Per-Thread State and Thread Control Block(TCB)
	For every thread the operating system creates,it creates one TCB.
	The thread control block holds two types of per-thread information:
		1.The state of the computation being performed by the thread.
		2.Metadata about the thread that is used to manage the thread.

Per-thread Computation State.
	a pointer to the thread's stack and a copy of its processor registers.

	Stack: A thread's stack is the same as the stack for a single-threaded computation -- it
	stores information needed by the nested procedures the thread is currently running.
	When a new thread is created, the operating system allocates it a new stack and
	stores a pointer to that stack in the thread's TCB.

	Copy of processor registers: A processor's registers include not only its general-purpose
	registers for storing intermediate values for ongoing computations, but they also include
	special-purpose registers, such as the instruction pointer and stack pointer.
	In some systems, the general-purpose registers for a stopped thread are stored on the top
	of the stack, and the TCB contains only a pointer to the stack.In other systems, the TCB
	contains space for a copy of all processor registers.

Per-thread Metadata.
	The TCB also includes per-thread metadata -- information for managing the thread. For
	example, each thread might have a thread ID, scheduling priority, and status (e.g,
	whether the thread is waiting for an event or is ready to be placed onto a processor).

Shared State
	program code is shared by all threads in a process, although each thread may be executing
	at a different place within that code. Additionally, statically allocated global variables
	and dynamically allocated heap variables can store information that is accessible to all
	threads.

In addition to the per-thread state that corresponds to execution state in the single-threaded
case,some systems include additional thread-local variables.These variables are similar to
global variables in that their scope spans different procedures, but they differ in that each
thread has its own copy of these variables.
Errno. In a multi-threaded program,however,multiple threads can perform system calls
concurrently.Rather than redefine the entire UNIX system call interface for a multi-threaded
environment, errno is now a macro that maps to a thread-local variable containing the error
code for that thread's most recent system call.
Heap internals. for performance reasons heaps may internally subdivide their space int 
per-thread regions.The advantage of subdividing the heap is that multiple threads can each
allocate objects at the same time without interfering with one anoter.Further, by allocating
objects used by the same thread from the same memory region, cache hit rates may improve.To
implement these optimizations, each subdivision of the heap has thread-local variables that
track what parts of the thread-local heap are in use, what parts are free,and so on.
Then, the code that allocates new memory is written to use these thread-local data structures
and only take memory from the shared heap if the local heap is empty.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Thread Life Cycle. What states does a thread go through between initialization and completion?

INIT：Thread creeation puts a thread into its INIT state and allocates and initializes 
per-thread data structures. Once that is done, thread creation code puts the thread into the
READY state by adding the thread to the ready list. In practice, the ready list is not in fact
a "list"; the operating system typically uses a more sophisticated data structure to keep 
track of runnable threads, such as a priority queue.

READY: Its TCB is on the ready list, and the values of its registers are stored in its TCB. At
any time, the scheduler can cause a thread to transition from READY to RUNNING by copying its
register values from its TCB to a processor's registers.

RUNNING: At this time, its register values are stored on the processor rathre than in the
TCB.A RUNNING thread can transition to the READY state in two ways:
	The scheduler can preempt a running thread and move it to the READY state by:
		1.saving the thread's registers to its TCB
		2.switching the processor to run the next thread on the ready list.
	A running thread can voluntarily relinquish the processor and go from RUNNING to READY by 
	calling yield (e.g.,thread_yield in the thread library).

WAITING: A thread in the WAITING state is waiting for some event. Whereas the scheduler can
move a thread in the READY state to the RUNNING state, a thread in the WAITING state cannot
run until some action by another moves it from WAITING to READY.After creating its children
threads, the main thread must wait for them complete, by calling thread_join once for each
child.If the specific child thread is not yet done at the time of the join, the main thread
goes from RUNNING to WAITING until the child thread exits.
While a thread waits for an event, it cannot make progress; therefore, it is not useful to run
it. Rather than continuing to run the thread or storing the TCB on the scheduler's ready list,
the TCB is stored on the waiting list of some synchronization variable associated with the 
event. When the required event occurs, the operating system moves the TCB from the
synchronization variable's waiting list to the scheduler's ready list, transitioning the thread
from WAITING to READY.

FINISHED: A thread in the FINISHED state never runs again. For example, the thread_exit call
lets a thread pass its exit value to its parent thread via thread_join.


Case: Where is my TCB?
A remarkably tricky implementation question is how to find the current thread's TCB. The thread
library needs access to the current TCB for a number of resons, e.g.,to change its priority or
to access thread-local variables.
The stack pointer is always unique to each thread. The thread library can store a pointer to
the thread TCB at the very bottom of the stack, underneath the procedure frames. (Some system
take this one step farther,and put the entire TCB at the bottom of the stack.) As long as
thread stacks are aligned to start at a fixed block boundary,the low order bits of the current
stack pointer can be masked to locate the pointer to the current TCB.
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Implementing Kernel Threads. How do we implement the thread abstraction inside the operating
system kernel?

-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Combining Kernel Threads and Single-Threaded User Processes. How do we extend the
implementation of kernel threads to support simple-threaded processes?
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Implementing Multi-threaded Processes. How do we implement the thread abstraction for 
multi-threaded applications?
-----------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------
Alternative Abstractions. What other abstractions can we use to express and implement
concurrency?
-----------------------------------------------------------------------------------------------
